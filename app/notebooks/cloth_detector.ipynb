{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from pathlib import Path\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=resnet34\n",
    "size=224\n",
    "\n",
    "aug_tfms = [RandomRotate(10, tfm_y=TfmType.COORD),\n",
    "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n",
    "            RandomFlip(tfm_y=TfmType.COORD)]\n",
    "tfms = tfms_from_model(f_model,\n",
    "                       size,\n",
    "                       crop_type=CropType.NO,\n",
    "                       tfm_y=TfmType.COORD,\n",
    "                       aug_tfms=aug_tfms)\n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)\n",
    "\n",
    "anc_grids = [28,14,7,4,2,1]\n",
    "anc_zooms =  [.7, 2**0, 2**(1/3), 2**(2/3)]\n",
    "anc_ratios = [(1.,1.), (.5,1.), (1.,.5), (3.,1.), (1.,3.)]\n",
    "\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n",
    "\n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, n_in,n_out,stride=2,dp = 0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_in,n_out,3,stride=stride,padding=1)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.dropout(self.bn(F.relu(self.conv(x))))\n",
    "    \n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, n_in, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.oconv1 = nn.Conv2d(n_in, (len(id2cat)+1) * k, 3, padding=1)\n",
    "        self.oconv2 = nn.Conv2d(n_in, 4 * k, 3, padding = 1)\n",
    "        self.oconv1.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return [flatten_conv(self.oconv1(x), self.k),\n",
    "                flatten_conv(self.oconv2(x), self.k)]\n",
    "\n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): \n",
    "        self.features = output\n",
    "        self.features_in = input\n",
    "    def remove(self): self.hook.remove()\n",
    "        \n",
    "cut,lr_cut = model_meta[f_model]\n",
    "def get_base():\n",
    "    layers = cut_model(f_model(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "drop = 0.4\n",
    "\n",
    "class SSD_Custom4(nn.Module):\n",
    "    def __init__(self, m_base, k, bias):\n",
    "        super().__init__()\n",
    "\n",
    "        self.m_base = m_base\n",
    "        self.sfs = [SaveFeatures(m_base[i]) for i in [5,6]] # 28, 14\n",
    "        \n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.layer2 = StdConv(512,256, dp=drop, stride=1) # 7\n",
    "        self.layer3 = StdConv(256,256, dp=drop) # 4\n",
    "        self.layer4 = StdConv(256,256, dp=drop) # 2\n",
    "        self.layer5 = StdConv(256,256, dp=drop) # 1\n",
    "        \n",
    "        self.lat6 = nn.Conv2d(256,256,kernel_size=1, stride=1, padding=0)\n",
    "        self.lat5 = nn.Conv2d(256,256,kernel_size=1, stride=1, padding=0)\n",
    "        self.lat4 = nn.Conv2d(256,256,kernel_size=1, stride=1, padding=0)\n",
    "        self.lat3 = nn.Conv2d(256,256,kernel_size=1, stride=1, padding=0)\n",
    "        self.lat2 = nn.Conv2d(256,256,kernel_size=1, stride=1, padding=0)\n",
    "        self.lat1 = nn.Conv2d(128,256,kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.upsamp2 = nn.Upsample(size=(2,2), mode='bilinear')\n",
    "        self.upsamp4 = nn.Upsample(size=(4,4), mode='bilinear')\n",
    "        self.upsamp7 = nn.Upsample(size=(7,7), mode='bilinear') # can't use nearest interpol for 4x4 -> 7x7\n",
    "        self.upsamp14 = nn.Upsample(size=(14,14), mode='bilinear')\n",
    "        self.upsamp28 = nn.Upsample(size=(28,28), mode='bilinear')\n",
    "        \n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "        self.out4 = OutConv(k, 256, bias)\n",
    "        self.out5 = OutConv(k, 256, bias)\n",
    "        self.out6 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.drop(F.relu(self.m_base(x)))\n",
    "        \n",
    "        c1 = F.relu(self.sfs[0].features) # 28\n",
    "        c2 = F.relu(self.sfs[1].features) # 14\n",
    "        c3 = self.layer2(x) # 7\n",
    "        c4 = self.layer3(c3) # 4\n",
    "        c5 = self.layer4(c4) # 2\n",
    "        c6 = self.layer5(c5) # 1\n",
    "       \n",
    "        p6 = self.lat6(c6)\n",
    "        p5 = self.upsamp2(p6) + self.lat5(c5)    \n",
    "        p4 = self.upsamp4(p5) + self.lat4(c4)\n",
    "        p3 = self.upsamp7(p4) + self.lat3(c3)\n",
    "        p2 = self.upsamp14(p3) + self.lat2(c2)\n",
    "        p1 = self.upsamp28(p2) + self.lat1(c1)\n",
    "        \n",
    "        o1c,o1l = self.out1(p1)\n",
    "        o2c,o2l = self.out2(p2)\n",
    "        o3c,o3l = self.out3(p3)\n",
    "        o4c,o4l = self.out4(p4)\n",
    "        o5c,o5l = self.out5(p5)\n",
    "        o6c,o6l = self.out6(p6)\n",
    "        \n",
    "        return [torch.cat([o1c,o2c,o3c,o4c,o5c,o6c], dim=1),\n",
    "                torch.cat([o1l,o2l,o3l,o4l,o5l,o6l], dim=1)]\n",
    "\n",
    "class MakeModel():\n",
    "    def __init__(self,model,name='makemodel'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.m_base), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "\n",
    "class Fake():\n",
    "    def __init__(self,p):\n",
    "        self.path = p\n",
    "\n",
    "def intersection(box_a,box_b):\n",
    "    min_xy = torch.max(box_a[:,None,:2],box_b[None,:,:2])\n",
    "    max_xy = torch.min(box_a[:,None,2:],box_b[None,:,2:])\n",
    "    inter = torch.clamp(max_xy-min_xy,min=0)\n",
    "    return inter[:,:,0] * inter[:,:,1]\n",
    "\n",
    "def get_size(box):\n",
    "    return (box[:,2]-box[:,0]) * (box[:,3] - box[:,1])\n",
    "\n",
    "def jaccard(box_a,box_b):\n",
    "    inter = intersection(box_a,box_b)\n",
    "    union = get_size(box_a).unsqueeze(1) + get_size(box_b).unsqueeze(0) - inter\n",
    "    return inter/union\n",
    "\n",
    "#Removes the zero padding in the target bbox/class\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/size\n",
    "    bb_keep = ((bbox[:,2] - bbox[:,0])>0.).nonzero()[:,0]\n",
    "    return bbox[bb_keep], clas[bb_keep]\n",
    "    \n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = actn\n",
    "    actn_ctrs = torch.clamp(((actn_bbs[:,:2] * grid_sizes) + anchors[:,:2]),0,size)\n",
    "    actn_hw = torch.clamp(((1 + actn_bbs[:,2:]) * anchors[:,2:]),0,size)\n",
    "    return hw2corners(actn_ctrs,actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    #if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def nms(boxes, scores, overlap=0.5, top_k=100):\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0: return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1: break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count\n",
    "\n",
    "def load_learner():\n",
    "    export = \"../models/export.pkl\"\n",
    "    state = torch.load(export)\n",
    "    id2cat = state.pop(\"classes\")\n",
    "    cat2id = {c:i for i,c in enumerate(id2cat)}\n",
    "    p = state.pop(\"path\")\n",
    "    mm = state.pop(\"model\")\n",
    "    c = state.pop(\"class\")\n",
    "    learn1 = c(Fake(Path(\"../../\")/p), mm)\n",
    "    learn1.load(\"fpn-modanet5\")\n",
    "    return learn1, id2cat, cat2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(learner, fn):\n",
    "    image = open_image(fn)\n",
    "    image = tfms[1](image, np.zeros(4))[0][None]\n",
    "    learner.model.cuda()\n",
    "    learner.model.eval()\n",
    "    pred_class,pred_bb = learner.model(V(image))\n",
    "    \n",
    "    a_ic = actn_to_bb(pred_bb[0], anchors)\n",
    "    clas_pr, clas_ids = pred_class[0].max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "    \n",
    "    conf_scores = pred_class[0].sigmoid().t().data\n",
    "    \n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > 0.25\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    \n",
    "    if not cc:\n",
    "        print(f\"{i}: empty array\")\n",
    "        return\n",
    "    \n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "    \n",
    "    return out2, cc, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_learner():\n",
    "    export = \"../models/export.pkl\"\n",
    "    state = torch.load(export)\n",
    "    id2cat = state.pop(\"classes\")\n",
    "    cat2id = {c:i for i,c in enumerate(id2cat)}\n",
    "    p = state.pop(\"path\")\n",
    "    mm = state.pop(\"model\")\n",
    "    c = state.pop(\"class\")\n",
    "    learn1 = c(Fake(Path(\"../../\")/p), mm)\n",
    "    learn1.load(\"fpn-modanet5\")\n",
    "    return learn1, id2cat, cat2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
