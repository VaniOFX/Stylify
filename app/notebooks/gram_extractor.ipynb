{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creator: Ivan Bardarov <br> (University of Strathclyde, March 2019)\n",
    "## This module extracts the gram matrix from an input photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from fastai.imports import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "class SaveFeatures():\n",
    "    \"\"\"\n",
    "    Registers a hook to a nn.Module and saves the activations in a variable\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    features : ndarray\n",
    "        The activations from the layer\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    hook_fn(module, input, output)\n",
    "        The callback function that is registered\n",
    "    close()\n",
    "        Remove the hook\n",
    "    \"\"\"\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def close(self): self.hook.remove()\n",
    "\n",
    "def gram(input):\n",
    "    \"\"\"\n",
    "    Calculates the gram matrix from a multidimensional array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : float.Tensor\n",
    "        The activations \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float.Tensor\n",
    "        the gram matrix\n",
    "\n",
    "    \"\"\"\n",
    "    b,c,h,w = input.size()\n",
    "    x = input.view(b*c, -1)\n",
    "    return torch.mm(x, x.t())/input.numel()*1e6\n",
    "\n",
    "def get_gram(filename):\n",
    "    \"\"\"\n",
    "    Processes an image and returns the gram matrix for it\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str, Path\n",
    "        The path to the input iamge\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        the gram matrix\n",
    "\n",
    "    \"\"\"\n",
    "    img = open_image(filename)\n",
    "    img_tfms = val_tfms(img)\n",
    "    m_vgg(VV(img_tfms[None]))\n",
    "    img_act = act.features.clone()\n",
    "    return to_np(gram(img_act).view(-1))\n",
    "\n",
    "# Setup the pretrained model\n",
    "m_vgg = to_gpu(vgg16(True)).eval()\n",
    "set_trainable(m_vgg, False)\n",
    "sz=288\n",
    "_, val_tfms = tfms_from_model(vgg16, sz)\n",
    "\n",
    "blocks = [i-1 for i,o in enumerate(children(m_vgg)) if isinstance(o,nn.MaxPool2d)]\n",
    "act = SaveFeatures(children(m_vgg)[blocks[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.conv.Conv2d"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(children(m_vgg)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [i-1 for i,o in enumerate(m_vgg) if isinstance(o,nn.MaxPool2d)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 12, 22, 32, 42]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
